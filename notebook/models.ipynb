{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix \n",
    "import warnings                        # To ignore any warnings \n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "dataset = pd.read_csv('loan_data_set.csv')\n",
    "\n",
    "\n",
    "print(dataset['Loan_Status'].value_counts())\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = 'Loan_Status', data=dataset, palette='hls')\n",
    "sns.set(rc={'axes.facecolor':'#f8f9fa', 'figure.facecolor':'#f8f9fa'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('loan_data_set.csv')\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print(dataset.columns[dataset.isnull().any()].tolist())\n",
    "missing_values = dataset.isnull()\n",
    "missing_values\n",
    "\n",
    "sns.heatmap(data = missing_values, yticklabels=False, cbar=False, cmap='viridis') #Heatmap of missing data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.countplot(x='Loan_Status', data=dataset, hue='Education') #comparing those who had the loan and those who didint based their educational background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# encoding the categorical features\n",
    "var_mod = ['Gender','Married','Dependents','Education','Self_Employed','Property_Area','Loan_Status']\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "    dataset[i] = le.fit_transform(dataset[i].astype(str))\n",
    "\n",
    "\n",
    "# spliting the dataset into features and labels\n",
    "X = pd.DataFrame(dataset.iloc[:, 1:-1]) #excluding Loan_ID\n",
    "y = pd.DataFrame(dataset.iloc[:,-1]).values.ravel() #just labels\n",
    "\n",
    "\n",
    "# imputing missing values for the features\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "imputer = imputer.fit(X)\n",
    "X = imputer.transform(X)\n",
    "\n",
    "# splitting dataset into train and test dataset\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Logistic Regression \n",
    "logistic_reg_model = LogisticRegression(solver='liblinear')\n",
    "logistic_reg_model.fit(x_train, y_train)\n",
    "y_pred = logistic_reg_model.predict(x_test)\n",
    "\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",recall_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "y_single = logistic_reg_model.predict(x_test[0].reshape(1, -1))\n",
    "\n",
    "\n",
    "# confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "class_names=[0,1] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model_decision_tree = DecisionTreeClassifier()\n",
    "model_decision_tree.fit(x_train,y_train)\n",
    "predictions = model_decision_tree.predict(x_test)\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(x_train,y_train)\n",
    "predictions = model.predict(x_test)\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=9)\n",
    "model.fit(x_train,y_train)\n",
    "predictions = model.predict(x_test)\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = SVC(gamma='scale', kernel='rbf')\n",
    "model.fit(x_train,y_train)\n",
    "predictions = model.predict(x_test)\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = dataset\n",
    "\n",
    "features = ['LP001486', 'Male','Yes','1','Not Graduate','No',4583,1508,128,360,1,'Rural','N']\n",
    "\n",
    "new_customer = pd.DataFrame({\n",
    "     'Loan_ID': [features[0]],\n",
    "     'Gender': [features[1]],\n",
    "     'Married': [features[2]],\n",
    "     'Dependents': [features[3]],\n",
    "     'Education': [features[4]],\n",
    "     'Self_Employed': [features[5]]\n",
    "     'ApplicantIncome': [features[6]],\n",
    "     'CoapplicantIncome': [features[7]],\n",
    "     'LoanAmount': [features[8]],\n",
    "     'Loan_Amount_Term': [features[9]],\n",
    "     'Credit_History': [features[10]],\n",
    "     'Property_Area':[features[11]],\n",
    "     'Loan_Status': [features[12]],\n",
    "})\n",
    "\n",
    "\n",
    "# append new single input to end of dataset\n",
    "dataset_test = dataset_test.append(new_customer)\n",
    "\n",
    "\n",
    "# encoding the categorical features\n",
    "var_mod = ['Gender','Married','Dependents','Education','Self_Employed','Property_Area','Loan_Status']\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "    dataset_test[i] = le.fit_transform(dataset_test[i].astype(str))\n",
    "\n",
    "    \n",
    "# extrating encoded user input from encoded dataset    \n",
    "user = dataset_test[-1:] # last row contains user data\n",
    "user = pd.DataFrame(user.iloc[:, 1:-1]) # exclude ID\n",
    "user.values\n",
    "\n",
    "y_single = model_decision_tree.predict(user.values) # Test encoded input on decision tress model\n",
    "print(y_single[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "dataset_1 = pd.read_csv('loan_data_set.csv')\n",
    "dataset_1 = dataset_1.drop('Loan_ID', axis=1)\n",
    "\n",
    "\n",
    "X = dataset_1.drop('Loan_Status', axis=1)\n",
    "y = dataset_1['Loan_Status']\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "\n",
    "# numeric_features = ['ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term']\n",
    "numeric_features = dataset_1.select_dtypes(include=['int64', 'float64']).columns\n",
    "numeric_features_steps = [('imputer', SimpleImputer(strategy='median')),('scaler', MinMaxScaler())]\n",
    "numeric_transformer = Pipeline(steps=numeric_features_steps)\n",
    "\n",
    "\n",
    "\n",
    "# categorical_features = ['Gender','Married','Dependents','Education','Self_Employed','Property_Area']\n",
    "categorical_features = dataset_1.select_dtypes(include=['object']).drop(['Loan_Status'], axis=1).columns\n",
    "categorical_features_steps = [('imputer', SimpleImputer(strategy='constant', fill_value='missing')),('onehot', OneHotEncoder())]\n",
    "categorical_transformer = Pipeline(steps=categorical_features_steps)\n",
    "\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    remainder = 'passthrough',\n",
    "    transformers=[\n",
    "    ('numeric', numeric_transformer, numeric_features),\n",
    "    ('categorical', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "classifiers = {\n",
    "    'K-Nearnest Neighbour': KNeighborsClassifier(9),\n",
    "    'Logistic Regression(solver=liblinear)': LogisticRegression(solver='liblinear'),\n",
    "    'Support Vector Machine(gamma=auto, kernel=rbf)': SVC(gamma='auto', kernel='rbf'),\n",
    "    'Support Vector Machine(kernel=\"rbf\", C=0.025, probability=True)': SVC(gamma='auto', kernel=\"rbf\", C=0.025, \n",
    "                                                                           probability=True),\n",
    "    'Nu Support Vector Machine(probability=True)': NuSVC(gamma='auto', probability=True),\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
    "    'Random Forest Classifier': RandomForestClassifier(n_estimators=100),\n",
    "    'AdaBoost Classifier': AdaBoostClassifier(),\n",
    "    'Gradient Boosting Classifier': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "\n",
    "pred_models = []\n",
    "\n",
    "for name, classifier in classifiers.items():\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', classifier)])\n",
    "    \n",
    "    pipe.fit(x_train, y_train)\n",
    "    pred_models.append(pipe)\n",
    "    \n",
    "y_pred = pred_models[1].predict(x_test)\n",
    "# print(\"Accuracy: %.4f\" % pred_models[1].score(x_test, y_test))\n",
    "\n",
    "x_test\n",
    "\n",
    "\n",
    "# for name, classifier in classifiers.items():\n",
    "#     pipe = Pipeline(steps=[('preprocessor', preprocessor),('classifier', classifier)])\n",
    "#     pipe.fit(x_train, y_train)\n",
    "#     y_pred = pipe.predict(x_test)\n",
    "#     print(\"Classifier: \", name)\n",
    "#     print(\"Accuracy: %.4f\" % pipe.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['LP001486', 'Male', 'Yes', '1', 'Graduate', 'No', 5483, 1508, 128, 360, 0, 'Urban', 'N']\n",
    "\n",
    "new_customer = pd.DataFrame({\n",
    "     'Gender': [features[1]],\n",
    "     'Married': [features[2]],\n",
    "     'Dependents': [features[3]],\n",
    "     'Education': [features[4]],\n",
    "     'Self_Employed': [features[5]],\n",
    "     'ApplicantIncome': [features[6]],\n",
    "     'CoapplicantIncome': [features[7]],\n",
    "     'LoanAmount': [features[8]],\n",
    "     'Loan_Amount_Term': [features[9]],\n",
    "     'Credit_History': [features[10]],\n",
    "     'Property_Area':[features[11]],\n",
    "})\n",
    "\n",
    "\n",
    "y_pred_single = pred_models[1].predict(new_customer)\n",
    "# print(y_pred_single[0])\n",
    "\n",
    "if y_pred_single[0] == 'Y':\n",
    "    print('Yes, you\\'re eligible')\n",
    "else:\n",
    "    print('Sorry, you\\'re not eligible')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\housing_main\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\housing_main\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\housing_main\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\housing_main\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\housing_main\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\housing_main\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\housing_main\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\housing_main\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\housing_main\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\housing_main\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.769515 (0.048411)\n",
      "LDA: 0.773462 (0.051592)\n",
      "KNN: 0.726555 (0.061821)\n",
      "CART: 0.704357 (0.060457)\n",
      "NB: 0.755178 (0.042766)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\housing_main\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\housing_main\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\housing_main\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\housing_main\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\housing_main\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\housing_main\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\housing_main\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\housing_main\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\housing_main\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\housing_main\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: 0.651025 (0.072141)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "# load dataset\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "# prepare configuration for cross validation test harness\n",
    "seed = 7\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
